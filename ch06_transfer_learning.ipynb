{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a34b0261-898d-4bef-ac14-30b8859350b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] torch/torchvision versions not as required, installing nightly versions.\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.12/site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in /opt/anaconda3/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "torch version: 2.6.0\n",
      "torchvision version: 0.21.0\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    import torch\n",
    "    import torchvision\n",
    "    assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n",
    "    assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n",
    "    print(f\"torch version: {torch.__version__}\")\n",
    "    print(f\"torchvision version: {torchvision.__version__}\")\n",
    "except:\n",
    "    print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\n",
    "    !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "    import torch\n",
    "    import torchvision\n",
    "    print(f\"torch version: {torch.__version__}\")\n",
    "    print(f\"torchvision version: {torchvision.__version__}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c82d89eb-785c-4da8-ba91-ee6f39a0657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "\n",
    "from going_modular import data_setup, engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "59ada371-3460-4d0b-b8e1-9fa5caf463b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=\"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b111c7b9-42ea-462f-86b8-b9701dfbcb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/pizza_steak_sushi directory exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "\n",
    "# Setup path to data folder\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "# If the image folder doesn't exist, download it and prepare it... \n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} directory exists.\")\n",
    "else:\n",
    "    print(f\"Did not find {image_path} directory, creating one...\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Download pizza, steak, sushi data\n",
    "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "        print(\"Downloading pizza, steak, sushi data...\")\n",
    "        f.write(request.content)\n",
    "\n",
    "    # Unzip pizza, steak, sushi data\n",
    "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
    "        print(\"Unzipping pizza, steak, sushi data...\") \n",
    "        zip_ref.extractall(image_path)\n",
    "\n",
    "    # Remove .zip file\n",
    "    os.remove(data_path / \"pizza_steak_sushi.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "79cef2c9-0d7f-49fe-90b0-48b09f6cd2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Dirs\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f79dbf-ac7b-492f-a2de-35fdccefa4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5eca6630",
   "metadata": {},
   "source": [
    "### Bring input data to the same transformations used for pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b21ebfd-41dd-4f59-84cc-d6583c6e4732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transforms pipeline manually (required for torchvision < 0.13)\n",
    "manual_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
    "    transforms.ToTensor(), # 2. Turn image values to between 0 & 1 \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
    "                         std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "269a6129-0e6d-4c04-a8b3-5999bd3f2916",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, test_dataloader, class_names=data_setup.create_dataloaders(train_dir,test_dir,transform=manual_transforms,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7fc00021-c292-4bcf-9e92-1adc6e4b31f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[ 0.5193,  0.6906,  0.8961,  ...,  2.2318,  2.2318,  2.2318],\n",
       "           [ 0.5536,  0.7248,  0.9646,  ...,  2.2318,  2.2318,  2.2318],\n",
       "           [ 0.6392,  0.8276,  1.0844,  ...,  2.2318,  2.2318,  2.2318],\n",
       "           ...,\n",
       "           [-1.4158, -1.4158, -1.4329,  ..., -0.9363, -0.9363, -0.9192],\n",
       "           [-1.4672, -1.5014, -1.5185,  ..., -0.9705, -1.0048, -1.0048],\n",
       "           [-1.5014, -1.5699, -1.6213,  ..., -1.0733, -1.1075, -1.1418]],\n",
       " \n",
       "          [[ 0.7304,  0.9055,  1.1155,  ...,  2.4111,  2.4111,  2.4111],\n",
       "           [ 0.7654,  0.9405,  1.1856,  ...,  2.4111,  2.4111,  2.4111],\n",
       "           [ 0.8529,  1.0455,  1.3081,  ...,  2.4111,  2.4111,  2.4111],\n",
       "           ...,\n",
       "           [-1.3354, -1.3354, -1.3529,  ..., -0.8627, -0.8627, -0.8627],\n",
       "           [-1.4230, -1.4405, -1.4580,  ..., -0.9153, -0.9503, -0.9503],\n",
       "           [-1.4755, -1.5280, -1.5630,  ..., -1.0203, -1.0553, -1.0903]],\n",
       " \n",
       "          [[ 0.9319,  1.1062,  1.3328,  ...,  2.6226,  2.6226,  2.6226],\n",
       "           [ 0.9668,  1.1585,  1.4200,  ...,  2.6226,  2.6226,  2.6226],\n",
       "           [ 1.0888,  1.2805,  1.5420,  ...,  2.6226,  2.6226,  2.6226],\n",
       "           ...,\n",
       "           [-1.3339, -1.3164, -1.3339,  ..., -0.8110, -0.8110, -0.8110],\n",
       "           [-1.4036, -1.4210, -1.4384,  ..., -0.8284, -0.8458, -0.8633],\n",
       "           [-1.4559, -1.5081, -1.5256,  ..., -0.8981, -0.9330, -0.9504]]],\n",
       " \n",
       " \n",
       "         [[[-1.9467, -1.9295, -1.9467,  ..., -2.0665, -2.0665, -2.0494],\n",
       "           [-1.9638, -1.9295, -1.9124,  ..., -2.0837, -2.0665, -2.0323],\n",
       "           [-1.9295, -1.8782, -1.8439,  ..., -2.0665, -2.0665, -2.0494],\n",
       "           ...,\n",
       "           [ 1.2043,  1.2214,  1.2214,  ...,  0.6563,  0.6392,  0.5536],\n",
       "           [ 1.1872,  1.2043,  1.1700,  ...,  0.6906,  0.6563,  0.6221],\n",
       "           [ 0.9474,  1.0159,  1.1015,  ...,  0.7419,  0.6563,  0.5536]],\n",
       " \n",
       "          [[-1.9657, -1.9307, -1.9307,  ..., -2.0007, -2.0007, -1.9832],\n",
       "           [-1.9832, -1.9307, -1.8957,  ..., -2.0182, -2.0007, -1.9657],\n",
       "           [-1.9482, -1.8782, -1.8256,  ..., -2.0007, -2.0007, -1.9832],\n",
       "           ...,\n",
       "           [ 0.8880,  0.9230,  0.9405,  ...,  0.8004,  0.7654,  0.6779],\n",
       "           [ 0.7829,  0.8354,  0.8354,  ...,  0.8179,  0.7829,  0.7479],\n",
       "           [ 0.5028,  0.6078,  0.7479,  ...,  0.8704,  0.7829,  0.6779]],\n",
       " \n",
       "          [[-1.7347, -1.7173, -1.7173,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [-1.7522, -1.7173, -1.6824,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [-1.7173, -1.6476, -1.6127,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           ...,\n",
       "           [ 0.4265,  0.4614,  0.4788,  ...,  1.0714,  1.0539,  0.9668],\n",
       "           [ 0.2871,  0.3393,  0.3568,  ...,  1.1411,  1.0888,  1.0714],\n",
       "           [-0.0441,  0.0779,  0.2348,  ...,  1.2108,  1.1237,  1.0365]]],\n",
       " \n",
       " \n",
       "         [[[ 0.8276,  0.8618,  0.9817,  ..., -1.9295, -1.5357, -1.2959],\n",
       "           [ 0.8104,  0.8276,  0.9988,  ..., -1.9467, -1.5528, -1.0390],\n",
       "           [ 0.7077,  0.8618,  0.9646,  ..., -1.9295, -1.4843, -0.8507],\n",
       "           ...,\n",
       "           [ 0.4679,  0.4337,  0.4508,  ...,  0.3138,  0.3309,  0.3138],\n",
       "           [ 0.5536,  0.5193,  0.4679,  ...,  0.3481,  0.3481,  0.3652],\n",
       "           [ 0.6049,  0.6049,  0.5707,  ...,  0.4166,  0.4166,  0.4337]],\n",
       " \n",
       "          [[-0.9153, -0.6702, -0.3725,  ..., -1.7031, -1.3529, -1.1604],\n",
       "           [-1.0378, -0.8102, -0.4076,  ..., -1.7206, -1.3529, -0.8803],\n",
       "           [-1.2654, -0.9153, -0.4951,  ..., -1.7031, -1.2829, -0.6527],\n",
       "           ...,\n",
       "           [ 0.6254,  0.5903,  0.5903,  ..., -0.0049, -0.0049, -0.0224],\n",
       "           [ 0.7129,  0.6429,  0.5903,  ..., -0.0049, -0.0049,  0.0126],\n",
       "           [ 0.7129,  0.7129,  0.6604,  ...,  0.0651,  0.0651,  0.0826]],\n",
       " \n",
       "          [[-0.2881, -0.0790,  0.1999,  ..., -1.2119, -0.8458, -0.6367],\n",
       "           [-0.4101, -0.2184,  0.1651,  ..., -1.2293, -0.8633, -0.3927],\n",
       "           [-0.6367, -0.3230,  0.0605,  ..., -1.2467, -0.8110, -0.2010],\n",
       "           ...,\n",
       "           [ 0.7054,  0.6356,  0.6356,  ..., -0.2707, -0.2358, -0.2358],\n",
       "           [ 0.7576,  0.7054,  0.6356,  ..., -0.2358, -0.2010, -0.1835],\n",
       "           [ 0.7576,  0.7751,  0.7576,  ..., -0.1487, -0.1312, -0.0790]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.3309,  0.3823,  0.4166,  ...,  0.0741, -0.0629, -0.2684],\n",
       "           [ 0.2796,  0.2624,  0.2111,  ...,  0.1083,  0.0056, -0.2171],\n",
       "           [ 0.1768,  0.1426,  0.1254,  ...,  0.1254,  0.1083,  0.0398],\n",
       "           ...,\n",
       "           [-1.6898, -1.7240, -1.7240,  ..., -1.7754, -1.7754, -1.7754],\n",
       "           [-2.0665, -2.0837, -2.0837,  ..., -1.7240, -1.7925, -1.8097],\n",
       "           [-2.0665, -2.0665, -2.0665,  ..., -1.7583, -1.7583, -1.7754]],\n",
       " \n",
       "          [[-0.6527, -0.6527, -0.6877,  ..., -0.4776, -0.5826, -0.7752],\n",
       "           [-0.7577, -0.8277, -0.9328,  ..., -0.4251, -0.5126, -0.7227],\n",
       "           [-0.8627, -0.9153, -0.9503,  ..., -0.4076, -0.4076, -0.4776],\n",
       "           ...,\n",
       "           [-1.5805, -1.6155, -1.6331,  ..., -1.9307, -1.9307, -1.9307],\n",
       "           [-1.9832, -2.0007, -1.9832,  ..., -1.8782, -1.9482, -1.9657],\n",
       "           [-1.9832, -1.9832, -1.9832,  ..., -1.8957, -1.9132, -1.9307]],\n",
       " \n",
       "          [[-1.3164, -1.2641, -1.2467,  ..., -0.7761, -0.7936, -0.9156],\n",
       "           [-1.3687, -1.4210, -1.4559,  ..., -0.7413, -0.7413, -0.8807],\n",
       "           [-1.4036, -1.4210, -1.4036,  ..., -0.7238, -0.6367, -0.6541],\n",
       "           ...,\n",
       "           [-1.4559, -1.5256, -1.5779,  ..., -1.7522, -1.7522, -1.7522],\n",
       "           [-1.7696, -1.8044, -1.8044,  ..., -1.7347, -1.7696, -1.7870],\n",
       "           [-1.7522, -1.7696, -1.7870,  ..., -1.7696, -1.7522, -1.7522]]],\n",
       " \n",
       " \n",
       "         [[[-2.0837, -2.1008, -2.1008,  ..., -1.8782, -1.8782, -1.8610],\n",
       "           [-2.0837, -2.1008, -2.1008,  ..., -1.8953, -1.9124, -1.8953],\n",
       "           [-2.0837, -2.1008, -2.1008,  ..., -1.9124, -1.9295, -1.8610],\n",
       "           ...,\n",
       "           [-1.6727, -1.6384, -1.5185,  ..., -2.0494, -2.0494, -2.0323],\n",
       "           [-1.7754, -1.7412, -1.6384,  ..., -2.0494, -2.0494, -2.0323],\n",
       "           [-1.8268, -1.7754, -1.6727,  ..., -2.0665, -2.0665, -2.0494]],\n",
       " \n",
       "          [[-1.9657, -1.9832, -1.9832,  ..., -1.6856, -1.7031, -1.7031],\n",
       "           [-1.9657, -1.9832, -1.9832,  ..., -1.7031, -1.7381, -1.7381],\n",
       "           [-1.9657, -1.9832, -1.9832,  ..., -1.7206, -1.7731, -1.7031],\n",
       "           ...,\n",
       "           [-1.6506, -1.6331, -1.5280,  ..., -1.9832, -1.9832, -1.9657],\n",
       "           [-1.7031, -1.6856, -1.6506,  ..., -1.9832, -1.9832, -1.9657],\n",
       "           [-1.7206, -1.7031, -1.6856,  ..., -2.0007, -2.0007, -1.9832]],\n",
       " \n",
       "          [[-1.7522, -1.7696, -1.7696,  ..., -1.4559, -1.4559, -1.4559],\n",
       "           [-1.7522, -1.7696, -1.7696,  ..., -1.4733, -1.5081, -1.5081],\n",
       "           [-1.7522, -1.7696, -1.7696,  ..., -1.5081, -1.5604, -1.4907],\n",
       "           ...,\n",
       "           [-1.7696, -1.7522, -1.6650,  ..., -1.7870, -1.7870, -1.7696],\n",
       "           [-1.6650, -1.6824, -1.6999,  ..., -1.7870, -1.7870, -1.7696],\n",
       "           [-1.5256, -1.5604, -1.6302,  ..., -1.8044, -1.8044, -1.7870]]],\n",
       " \n",
       " \n",
       "         [[[ 2.0263,  1.9749,  1.9235,  ..., -0.0116, -0.2856, -0.6109],\n",
       "           [ 1.9749,  1.9064,  1.8722,  ...,  0.1426,  0.0912, -0.0629],\n",
       "           [ 1.9749,  1.9407,  1.8893,  ...,  0.1939,  0.1426,  0.1254],\n",
       "           ...,\n",
       "           [ 2.0777,  2.0605,  2.1119,  ...,  0.1939, -0.2342, -0.3541],\n",
       "           [ 2.0948,  2.0777,  2.0777,  ...,  0.1597, -0.2513, -0.3027],\n",
       "           [ 2.0948,  2.0948,  2.0948,  ...,  0.5022, -0.0972, -0.2684]],\n",
       " \n",
       "          [[ 1.8683,  1.8333,  1.7983,  ..., -0.9678, -1.1954, -1.4930],\n",
       "           [ 1.8333,  1.7808,  1.7633,  ..., -0.8277, -0.8452, -0.9853],\n",
       "           [ 1.8683,  1.8333,  1.7808,  ..., -0.8102, -0.8452, -0.8627],\n",
       "           ...,\n",
       "           [ 1.6057,  1.5882,  1.6232,  ..., -0.3550, -0.4951, -0.4251],\n",
       "           [ 1.6408,  1.6057,  1.6057,  ..., -0.4776, -0.5651, -0.3901],\n",
       "           [ 1.6408,  1.6408,  1.6057,  ..., -0.1975, -0.4601, -0.3901]],\n",
       " \n",
       "          [[ 1.4722,  1.4722,  1.4722,  ..., -1.3861, -1.5256, -1.6999],\n",
       "           [ 1.4548,  1.4200,  1.4025,  ..., -1.2816, -1.2467, -1.3339],\n",
       "           [ 1.5071,  1.4548,  1.3677,  ..., -1.3164, -1.3164, -1.2990],\n",
       "           ...,\n",
       "           [-0.2010, -0.1835, -0.1138,  ..., -0.6890, -0.5147, -0.2532],\n",
       "           [-0.2184, -0.2010, -0.1487,  ..., -0.8981, -0.6367, -0.2010],\n",
       "           [-0.2707, -0.2010, -0.1312,  ..., -0.6715, -0.5670, -0.2358]]]]),\n",
       " tensor([1, 1, 0, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 0, 0, 2, 1, 1, 1, 1,\n",
       "         0, 1, 1, 1, 2, 2, 2, 0])]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9491b90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pizza', 'steak', 'sushi']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b26e7e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet_B0_Weights.IMAGENET1K_V1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get the transforms used for pre trained model automatically without manual trabnsformas (update after torch 0.13)\n",
    "# Get a set of pretrained model weights\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # .DEFAULT = best available weights from pretraining on ImageNet\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "414d051b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=[224]\n",
       "    resize_size=[256]\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BICUBIC\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_transforms=weights.transforms()\n",
    "auto_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e63a763",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, test_dataloader, class_names=data_setup.create_dataloaders(train_dir,test_dir,transform=auto_transforms,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1856f0",
   "metadata": {},
   "source": [
    "## Get pretrained model from torchvision.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f95280",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "model=torchvision.models.efficientnet_b0(weights=weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "19f7f117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "EfficientNet                                            --\n",
       "├─Sequential: 1-1                                       --\n",
       "│    └─Conv2dNormActivation: 2-1                        --\n",
       "│    │    └─Conv2d: 3-1                                 864\n",
       "│    │    └─BatchNorm2d: 3-2                            64\n",
       "│    │    └─SiLU: 3-3                                   --\n",
       "│    └─Sequential: 2-2                                  --\n",
       "│    │    └─MBConv: 3-4                                 1,448\n",
       "│    └─Sequential: 2-3                                  --\n",
       "│    │    └─MBConv: 3-5                                 6,004\n",
       "│    │    └─MBConv: 3-6                                 10,710\n",
       "│    └─Sequential: 2-4                                  --\n",
       "│    │    └─MBConv: 3-7                                 15,350\n",
       "│    │    └─MBConv: 3-8                                 31,290\n",
       "│    └─Sequential: 2-5                                  --\n",
       "│    │    └─MBConv: 3-9                                 37,130\n",
       "│    │    └─MBConv: 3-10                                102,900\n",
       "│    │    └─MBConv: 3-11                                102,900\n",
       "│    └─Sequential: 2-6                                  --\n",
       "│    │    └─MBConv: 3-12                                126,004\n",
       "│    │    └─MBConv: 3-13                                208,572\n",
       "│    │    └─MBConv: 3-14                                208,572\n",
       "│    └─Sequential: 2-7                                  --\n",
       "│    │    └─MBConv: 3-15                                262,492\n",
       "│    │    └─MBConv: 3-16                                587,952\n",
       "│    │    └─MBConv: 3-17                                587,952\n",
       "│    │    └─MBConv: 3-18                                587,952\n",
       "│    └─Sequential: 2-8                                  --\n",
       "│    │    └─MBConv: 3-19                                717,232\n",
       "│    └─Conv2dNormActivation: 2-9                        --\n",
       "│    │    └─Conv2d: 3-20                                409,600\n",
       "│    │    └─BatchNorm2d: 3-21                           2,560\n",
       "│    │    └─SiLU: 3-22                                  --\n",
       "├─AdaptiveAvgPool2d: 1-2                                --\n",
       "├─Sequential: 1-3                                       --\n",
       "│    └─Dropout: 2-10                                    --\n",
       "│    └─Linear: 2-11                                     1,281,000\n",
       "================================================================================\n",
       "Total params: 5,288,548\n",
       "Trainable params: 5,288,548\n",
       "Non-trainable params: 0\n",
       "================================================================================"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8e1ade9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): SiLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
      "      )\n",
      "      (3): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (8): Conv2dNormActivation(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): SiLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=True)\n",
      "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a3f7c10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "EfficientNet (EfficientNet)                                  [32, 3, 224, 224]    [32, 3]              --                   Partial\n",
       "├─Sequential (features)                                      [32, 3, 224, 224]    [32, 1280, 7, 7]     --                   False\n",
       "│    └─Conv2dNormActivation (0)                              [32, 3, 224, 224]    [32, 32, 112, 112]   --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 3, 224, 224]    [32, 32, 112, 112]   (864)                False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112]   [32, 32, 112, 112]   (64)                 False\n",
       "│    │    └─SiLU (2)                                         [32, 32, 112, 112]   [32, 32, 112, 112]   --                   --\n",
       "│    └─Sequential (1)                                        [32, 32, 112, 112]   [32, 16, 112, 112]   --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 32, 112, 112]   [32, 16, 112, 112]   (1,448)              False\n",
       "│    └─Sequential (2)                                        [32, 16, 112, 112]   [32, 24, 56, 56]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 16, 112, 112]   [32, 24, 56, 56]     (6,004)              False\n",
       "│    │    └─MBConv (1)                                       [32, 24, 56, 56]     [32, 24, 56, 56]     (10,710)             False\n",
       "│    └─Sequential (3)                                        [32, 24, 56, 56]     [32, 40, 28, 28]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 24, 56, 56]     [32, 40, 28, 28]     (15,350)             False\n",
       "│    │    └─MBConv (1)                                       [32, 40, 28, 28]     [32, 40, 28, 28]     (31,290)             False\n",
       "│    └─Sequential (4)                                        [32, 40, 28, 28]     [32, 80, 14, 14]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 40, 28, 28]     [32, 80, 14, 14]     (37,130)             False\n",
       "│    │    └─MBConv (1)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     (102,900)            False\n",
       "│    │    └─MBConv (2)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     (102,900)            False\n",
       "│    └─Sequential (5)                                        [32, 80, 14, 14]     [32, 112, 14, 14]    --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 80, 14, 14]     [32, 112, 14, 14]    (126,004)            False\n",
       "│    │    └─MBConv (1)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    (208,572)            False\n",
       "│    │    └─MBConv (2)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    (208,572)            False\n",
       "│    └─Sequential (6)                                        [32, 112, 14, 14]    [32, 192, 7, 7]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 112, 14, 14]    [32, 192, 7, 7]      (262,492)            False\n",
       "│    │    └─MBConv (1)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    │    └─MBConv (2)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    │    └─MBConv (3)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    └─Sequential (7)                                        [32, 192, 7, 7]      [32, 320, 7, 7]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 192, 7, 7]      [32, 320, 7, 7]      (717,232)            False\n",
       "│    └─Conv2dNormActivation (8)                              [32, 320, 7, 7]      [32, 1280, 7, 7]     --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 320, 7, 7]      [32, 1280, 7, 7]     (409,600)            False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 1280, 7, 7]     [32, 1280, 7, 7]     (2,560)              False\n",
       "│    │    └─SiLU (2)                                         [32, 1280, 7, 7]     [32, 1280, 7, 7]     --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)                                [32, 1280, 7, 7]     [32, 1280, 1, 1]     --                   --\n",
       "├─Sequential (classifier)                                    [32, 1280]           [32, 3]              --                   True\n",
       "│    └─Dropout (0)                                           [32, 1280]           [32, 1280]           --                   --\n",
       "│    └─Linear (1)                                            [32, 1280]           [32, 3]              3,843                True\n",
       "============================================================================================================================================\n",
       "Total params: 4,011,391\n",
       "Trainable params: 3,843\n",
       "Non-trainable params: 4,007,548\n",
       "Total mult-adds (Units.GIGABYTES): 12.31\n",
       "============================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3452.09\n",
       "Params size (MB): 16.05\n",
       "Estimated Total Size (MB): 3487.41\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a summary using torchinfo (uncomment for actual output)\n",
    "summary(model=model, \n",
    "        input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\"\n",
    "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ea05a88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Freeze feature extraction layer \n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8484a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update classifier head to our custom problem\n",
    "output_features=len(class_names)\n",
    "model.classifier = torch.nn.Sequential(\n",
    "    nn.Dropout(p=0.2,inplace = True),\n",
    "    nn.Linear(in_features= 1280, out_features= output_features, bias=True )\n",
    "    \n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f155045c",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4886d7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0f4548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d84710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3108e3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 1.2156e-01,  6.5634e-01,  4.5671e-01],\n",
       "          [-1.1092e-01, -6.1004e-01, -3.3345e-01],\n",
       "          [ 2.7964e-02, -1.0312e-01, -1.0324e-01]],\n",
       "\n",
       "         [[ 6.3553e-02,  1.6552e+00,  1.7436e+00],\n",
       "          [-1.3646e-01, -1.5367e+00, -1.5937e+00],\n",
       "          [ 5.0196e-02, -1.1360e-01, -1.2600e-01]],\n",
       "\n",
       "         [[ 8.7276e-02,  3.6126e-01,  2.6946e-01],\n",
       "          [-1.1966e-01, -2.8122e-01, -2.1883e-01],\n",
       "          [ 3.6658e-02, -7.0751e-02, -8.1917e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.6449e-01, -2.0041e-01,  8.3092e-02],\n",
       "          [ 8.9009e-01, -1.2110e+00,  2.7610e-01],\n",
       "          [ 1.0740e+00, -1.2603e+00,  2.0645e-01]],\n",
       "\n",
       "         [[ 3.2816e-01, -4.3449e-01,  1.8769e-01],\n",
       "          [ 1.6213e+00, -2.1188e+00,  4.1014e-01],\n",
       "          [ 1.7230e+00, -2.0756e+00,  3.3958e-01]],\n",
       "\n",
       "         [[ 9.5290e-02, -1.5971e-01,  7.4559e-02],\n",
       "          [ 8.0502e-01, -9.7034e-01,  2.6280e-01],\n",
       "          [ 7.1944e-01, -1.0026e+00,  1.9870e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 5.3857e-02,  2.6367e-01,  1.1696e-01],\n",
       "          [ 9.1437e-03, -4.0163e-01, -2.9987e-02],\n",
       "          [ 5.0206e-02, -9.4240e-02,  2.1124e-02]],\n",
       "\n",
       "         [[-3.2397e-02,  6.4322e-01,  7.0337e-01],\n",
       "          [ 6.1792e-02, -5.8830e-01, -7.6228e-01],\n",
       "          [ 7.1294e-03, -2.4078e-02, -3.3752e-02]],\n",
       "\n",
       "         [[ 3.7394e-02,  8.7654e-02,  4.7056e-02],\n",
       "          [-7.1244e-02,  2.5078e-03, -3.5434e-02],\n",
       "          [-2.1194e-02, -1.6206e-02, -3.6308e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4140e-01,  1.2869e+00,  1.3137e+00],\n",
       "          [ 2.1771e-01, -1.1241e-01, -1.8626e-01],\n",
       "          [-3.9105e-01, -1.1449e+00, -1.1276e+00]],\n",
       "\n",
       "         [[ 5.3790e-01,  2.1495e+00,  2.1706e+00],\n",
       "          [ 2.0470e-01,  9.0613e-02, -9.8142e-02],\n",
       "          [-7.1019e-01, -2.1877e+00, -2.1587e+00]],\n",
       "\n",
       "         [[ 9.4827e-02,  8.0110e-01,  8.3132e-01],\n",
       "          [ 1.6479e-01, -1.7622e-01, -1.4895e-01],\n",
       "          [-2.9311e-01, -6.5122e-01, -6.1511e-01]]],\n",
       "\n",
       "\n",
       "        [[[-7.3552e-03,  4.8254e-01, -1.5625e-01],\n",
       "          [-4.0980e-01,  1.8959e-01, -2.0417e-01],\n",
       "          [ 4.3541e-02,  1.4331e-01, -5.4753e-02]],\n",
       "\n",
       "         [[-1.3115e-01,  6.9486e-01, -1.6917e-01],\n",
       "          [-6.3885e-01,  3.3350e-01, -2.9539e-01],\n",
       "          [ 6.1328e-02,  1.9726e-01, -6.8915e-02]],\n",
       "\n",
       "         [[-2.5814e-02,  4.0553e-01, -1.3976e-01],\n",
       "          [-3.4265e-01,  1.4483e-01, -1.3192e-01],\n",
       "          [ 6.3810e-02,  7.5440e-02, -3.2279e-02]]],\n",
       "\n",
       "\n",
       "        [[[-6.9120e-02, -6.8907e-02, -1.0110e-01],\n",
       "          [-1.8204e-01, -3.4398e-01, -3.3505e-01],\n",
       "          [-2.1337e-01, -3.8846e-01, -3.1723e-01]],\n",
       "\n",
       "         [[-2.6603e-03,  6.7322e-02,  2.0481e-01],\n",
       "          [ 1.7049e-01,  1.4370e+00,  8.4013e-01],\n",
       "          [ 2.5802e-01,  9.5905e-01,  6.9388e-01]],\n",
       "\n",
       "         [[-2.9915e-02, -1.9313e-01, -6.2866e-02],\n",
       "          [-2.9906e-01, -7.1696e-01, -5.6458e-01],\n",
       "          [-2.0027e-01, -5.3640e-01, -2.7108e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.1014e-02,  7.2219e-02, -5.8973e-02],\n",
       "          [ 5.7481e-02,  1.4757e-01,  8.3812e-03],\n",
       "          [-5.9831e-02, -1.7216e-02, -9.6462e-02]],\n",
       "\n",
       "         [[-1.4164e-01,  1.5137e-01, -4.7108e-02],\n",
       "          [ 1.3441e-01,  3.9927e-01,  2.2556e-01],\n",
       "          [-7.3653e-02,  1.8831e-01,  1.1634e-01]],\n",
       "\n",
       "         [[ 1.8965e-01,  4.3459e-01,  7.1190e-02],\n",
       "          [ 4.2824e-01,  4.2443e-01,  4.1345e-01],\n",
       "          [ 1.0391e-01,  1.7768e-01,  4.3779e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.6167e-02, -1.8666e-02, -2.4673e-02],\n",
       "          [ 3.3238e-02, -1.7968e-01, -1.4685e-01],\n",
       "          [-8.0528e-02, -3.9509e-01, -2.7428e-01]],\n",
       "\n",
       "         [[-9.5580e-03,  4.6433e-02,  2.9300e-02],\n",
       "          [ 2.6856e-02, -4.8462e-01, -3.6544e-01],\n",
       "          [-9.4869e-02, -7.0041e-01, -5.9449e-01]],\n",
       "\n",
       "         [[ 2.6508e-02, -1.8488e-02,  1.1762e-02],\n",
       "          [-6.5515e-04, -1.2137e-01, -8.3482e-02],\n",
       "          [-5.7830e-02, -2.3003e-01, -1.8690e-01]]],\n",
       "\n",
       "\n",
       "        [[[-5.3202e-02,  3.4638e-02,  7.8128e-03],\n",
       "          [ 4.1434e-02, -7.6196e-02, -2.3942e-01],\n",
       "          [ 1.3017e-02, -2.8619e-01, -4.2785e-01]],\n",
       "\n",
       "         [[-2.6868e-02,  1.1372e-01,  8.8856e-02],\n",
       "          [ 7.8053e-02, -2.9669e-01, -3.6891e-01],\n",
       "          [ 3.5080e-02, -5.7837e-01, -6.5849e-01]],\n",
       "\n",
       "         [[-2.2574e-02,  7.3312e-03,  5.1263e-02],\n",
       "          [ 2.1900e-03, -1.1663e-01, -1.8212e-01],\n",
       "          [ 2.1410e-02, -1.9747e-01, -3.6762e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 8.1612e-02,  6.3252e-02, -1.1599e-02],\n",
       "          [ 1.3115e-01, -2.4606e-01, -5.6886e-03],\n",
       "          [ 1.6400e-01, -1.1320e-01,  1.0798e-01]],\n",
       "\n",
       "         [[ 2.5764e-01,  4.8746e-02,  3.2580e-01],\n",
       "          [-1.4313e-01, -5.5514e-01,  1.1891e-02],\n",
       "          [-3.2060e-02, -3.8722e-01,  1.5970e-01]],\n",
       "\n",
       "         [[-2.5849e-01, -2.9012e-01, -3.0817e-01],\n",
       "          [-2.8199e-01, -1.9076e-01, -4.8173e-01],\n",
       "          [-3.0951e-01, -3.1268e-01, -4.7012e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 6.4594e-01,  6.3691e-01,  4.7947e-01],\n",
       "          [ 6.3545e-01,  3.9784e-01,  7.4985e-01],\n",
       "          [ 6.1847e-01,  7.1732e-01,  5.2129e-01]],\n",
       "\n",
       "         [[-5.4349e-02,  6.2490e-02, -1.5145e-01],\n",
       "          [ 6.0137e-02,  2.9433e-01,  1.6113e-01],\n",
       "          [-2.4608e-01,  1.0170e-01, -1.6264e-01]],\n",
       "\n",
       "         [[-1.1361e-02,  1.7383e-02,  1.8179e-02],\n",
       "          [ 8.6205e-03, -1.8093e-02, -1.7036e-02],\n",
       "          [ 3.7415e-02, -2.6508e-02, -6.2734e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 8.8970e-03, -5.9413e-02, -3.3523e-02],\n",
       "          [ 5.8187e-02,  8.0130e-01,  7.2454e-01],\n",
       "          [-1.5200e-01, -7.1680e-01, -6.0844e-01]],\n",
       "\n",
       "         [[ 2.3588e-02, -2.0343e-02, -7.4938e-03],\n",
       "          [ 1.1000e-01,  1.5724e+00,  1.1048e+00],\n",
       "          [-2.3134e-01, -1.2064e+00, -1.4127e+00]],\n",
       "\n",
       "         [[-1.1468e-02,  7.0898e-03, -2.9944e-02],\n",
       "          [ 4.4323e-02,  6.0679e-01,  4.9542e-01],\n",
       "          [-1.1081e-01, -5.7300e-01, -4.2440e-01]]],\n",
       "\n",
       "\n",
       "        [[[-5.7416e-02,  6.6622e-02, -9.5278e-02],\n",
       "          [ 1.5429e-01,  2.1161e-01,  3.7951e-02],\n",
       "          [ 9.9630e-02,  3.5816e-01,  1.5506e-01]],\n",
       "\n",
       "         [[-7.2265e-02,  9.5034e-03, -1.9102e-01],\n",
       "          [ 1.8391e-01,  6.4832e-01,  6.4051e-02],\n",
       "          [ 5.8232e-02,  7.0050e-01,  2.6434e-01]],\n",
       "\n",
       "         [[-3.6791e-02,  1.7033e-02,  6.4145e-03],\n",
       "          [ 1.7574e-01,  4.1436e-01, -1.0721e-02],\n",
       "          [ 4.0671e-02,  3.5527e-01, -4.6846e-02]]],\n",
       "\n",
       "\n",
       "        [[[-4.4645e-02,  2.3739e-02,  8.9418e-02],\n",
       "          [-1.6117e-02,  5.6504e-02,  1.4675e-01],\n",
       "          [ 1.6170e-01,  1.9881e-01,  4.9155e-02]],\n",
       "\n",
       "         [[-9.0149e-02, -2.9171e-03,  1.0447e-01],\n",
       "          [-5.4217e-02,  2.6691e-01,  1.5557e-01],\n",
       "          [ 1.4441e-01,  4.1680e-01,  2.0795e-01]],\n",
       "\n",
       "         [[-3.7583e-02,  3.8280e-02,  9.6811e-02],\n",
       "          [-7.4146e-02,  9.9193e-02,  6.2020e-02],\n",
       "          [ 8.1806e-02,  1.5332e-01,  5.6435e-03]]],\n",
       "\n",
       "\n",
       "        [[[-5.0655e-02, -5.9444e-01, -8.5282e-01],\n",
       "          [ 2.0286e-01,  1.1141e+00,  1.1980e+00],\n",
       "          [-1.3802e-01, -4.5542e-01, -4.1090e-01]],\n",
       "\n",
       "         [[-2.4583e-01, -1.1887e+00, -1.2131e+00],\n",
       "          [ 4.2132e-01,  1.9646e+00,  1.8692e+00],\n",
       "          [-2.3047e-01, -6.7137e-01, -7.1950e-01]],\n",
       "\n",
       "         [[-6.8945e-03, -4.7036e-01, -6.2787e-01],\n",
       "          [ 4.6393e-02,  8.8468e-01,  1.0159e+00],\n",
       "          [-4.7319e-02, -3.9375e-01, -4.1689e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.2574e-03, -5.8750e-03, -8.9063e-03],\n",
       "          [-9.5790e-02,  2.0353e-02,  7.6180e-02],\n",
       "          [ 3.8864e-01,  2.1756e-01, -5.7230e-01]],\n",
       "\n",
       "         [[-9.0207e-03,  5.4034e-02, -6.1153e-02],\n",
       "          [-1.2678e-01, -3.8776e-02,  9.9527e-02],\n",
       "          [ 5.6438e-01,  4.5655e-01, -9.1998e-01]],\n",
       "\n",
       "         [[ 2.1571e-02,  1.9349e-03, -9.9684e-03],\n",
       "          [-6.2921e-02,  1.2327e-02,  2.7703e-02],\n",
       "          [ 2.7333e-01,  1.8717e-01, -4.2031e-01]]],\n",
       "\n",
       "\n",
       "        [[[-7.9060e-03,  5.9474e-02, -7.1074e-02],\n",
       "          [ 4.7573e-02,  3.2671e-01, -4.0197e-01],\n",
       "          [ 7.4184e-02,  3.3043e-01, -2.7993e-01]],\n",
       "\n",
       "         [[-2.0074e-02,  1.1373e-01, -5.4404e-02],\n",
       "          [-5.5469e-03,  4.9988e-01, -3.0030e-01],\n",
       "          [-1.1499e-01,  4.0272e-01, -2.7360e-01]],\n",
       "\n",
       "         [[ 1.3825e-04,  2.3889e-02, -4.8133e-02],\n",
       "          [-2.4828e-02,  3.2425e-01, -3.0981e-01],\n",
       "          [-2.0210e-02,  3.4540e-01, -2.5380e-01]]],\n",
       "\n",
       "\n",
       "        [[[-7.0707e-02,  3.7815e-02,  6.7919e-02],\n",
       "          [ 1.0012e-03, -7.5575e-02, -2.6554e-01],\n",
       "          [ 2.8861e-02, -1.8928e-02, -3.1675e-01]],\n",
       "\n",
       "         [[ 4.4488e-02,  7.6318e-02,  2.5235e-02],\n",
       "          [ 1.3437e-01, -2.7695e-01, -5.3462e-01],\n",
       "          [ 1.4984e-01, -2.4638e-01, -6.3909e-01]],\n",
       "\n",
       "         [[-4.9667e-03,  6.8869e-02,  1.8387e-01],\n",
       "          [ 4.2543e-02, -2.4587e-02, -1.4325e-01],\n",
       "          [ 1.3501e-02, -1.6504e-01, -4.1547e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.8419e-02, -3.0055e-02,  5.3814e-02],\n",
       "          [-4.9959e-02, -2.7598e-01, -1.1108e-02],\n",
       "          [ 1.1776e-01,  5.8499e-02,  1.1630e-01]],\n",
       "\n",
       "         [[-3.4606e-01, -5.4840e-01, -2.6592e-01],\n",
       "          [-6.2674e-01, -9.0666e-01, -5.1259e-01],\n",
       "          [-3.1991e-01, -6.0945e-01, -2.7665e-01]],\n",
       "\n",
       "         [[ 4.2935e-01,  6.9317e-01,  1.7877e-01],\n",
       "          [ 7.6772e-01,  1.0664e+00,  4.7277e-01],\n",
       "          [ 1.7151e-01,  4.2932e-01,  2.0437e-01]]],\n",
       "\n",
       "\n",
       "        [[[-4.0116e-02,  1.8940e-01,  7.9245e-02],\n",
       "          [ 1.7987e-01,  9.5106e-01,  6.8831e-01],\n",
       "          [ 1.0832e-01,  7.0846e-01,  5.1219e-01]],\n",
       "\n",
       "         [[-9.6432e-02, -8.0753e-02, -7.5511e-02],\n",
       "          [-7.6573e-02, -1.3027e-01, -7.6444e-02],\n",
       "          [-6.3054e-02, -1.0113e-01, -2.2455e-02]],\n",
       "\n",
       "         [[ 1.2649e-01, -8.9891e-02, -2.1204e-02],\n",
       "          [-1.0740e-01, -8.3563e-01, -6.0009e-01],\n",
       "          [-3.7200e-03, -5.7180e-01, -4.5948e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.0877e-02, -5.2581e-04,  3.6006e-02],\n",
       "          [-8.1833e-03, -1.8894e-01, -2.7973e-01],\n",
       "          [ 4.8111e-02, -2.3845e-01, -3.9947e-01]],\n",
       "\n",
       "         [[-1.9805e-02,  3.6469e-02,  2.7337e-02],\n",
       "          [ 5.4739e-02, -2.6850e-01, -3.7385e-01],\n",
       "          [ 1.2839e-01, -3.7142e-01, -6.3831e-01]],\n",
       "\n",
       "         [[-4.4512e-03, -2.0684e-02, -1.6228e-02],\n",
       "          [-2.5255e-02, -1.4119e-01, -1.6355e-01],\n",
       "          [ 6.9882e-02, -1.9325e-01, -3.6468e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 7.1846e-02, -5.5242e-02, -5.7872e-02],\n",
       "          [-9.2421e-02, -3.0691e-01, -4.2403e-01],\n",
       "          [ 5.6014e-02, -1.0301e-01, -1.2842e-01]],\n",
       "\n",
       "         [[-6.6694e-02, -1.1122e-01,  9.8542e-03],\n",
       "          [-1.2751e-01, -4.2231e-01, -2.5336e-01],\n",
       "          [-3.3863e-02, -3.3140e-01, -1.1083e-01]],\n",
       "\n",
       "         [[ 4.5466e-02,  3.6818e-02,  1.0310e-01],\n",
       "          [ 5.2255e-02, -3.0455e-01, -1.1062e-01],\n",
       "          [ 4.8801e-02,  4.5952e-02,  1.7598e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0194e-01,  5.3175e-02,  9.6414e-02],\n",
       "          [ 1.2054e-01, -1.0107e-01,  6.2497e-02],\n",
       "          [-1.2825e-01, -4.9343e-01, -6.0227e-02]],\n",
       "\n",
       "         [[-7.3693e-02, -1.8710e-02,  1.0043e-02],\n",
       "          [-7.8110e-02, -4.7124e-02,  7.9967e-03],\n",
       "          [-1.5277e-02, -2.9438e-01, -2.4315e-01]],\n",
       "\n",
       "         [[ 3.8916e-02,  1.5737e-02,  5.7821e-02],\n",
       "          [-6.0568e-04,  1.2791e-02,  2.0366e-02],\n",
       "          [-7.9278e-02, -2.1829e-01, -1.5630e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.2183e-02,  5.2108e-02, -5.9305e-02],\n",
       "          [-9.0439e-02, -6.4628e-01, -6.1229e-01],\n",
       "          [-4.6458e-03,  6.7793e-01,  6.9062e-01]],\n",
       "\n",
       "         [[ 1.1845e-01,  2.7236e-02, -2.9530e-02],\n",
       "          [-1.6356e-01, -1.3374e+00, -1.3954e+00],\n",
       "          [ 1.7938e-02,  1.5309e+00,  1.1622e+00]],\n",
       "\n",
       "         [[-3.2158e-02,  8.7771e-02, -5.2187e-02],\n",
       "          [-9.6869e-03, -4.3989e-01, -4.1063e-01],\n",
       "          [-2.7748e-02,  4.1385e-01,  4.6556e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.4094e-02, -2.5755e-02, -3.1481e-02],\n",
       "          [-2.6426e-02, -1.7923e-02,  1.6756e-01],\n",
       "          [-5.1120e-02,  8.8820e-03,  6.2477e-01]],\n",
       "\n",
       "         [[ 5.8289e-02,  6.3699e-02,  7.6151e-02],\n",
       "          [ 1.2605e-01, -8.9339e-02, -1.5980e-02],\n",
       "          [ 1.5391e-01, -9.8014e-02,  3.3084e-01]],\n",
       "\n",
       "         [[-3.1520e-02, -5.2036e-02, -7.0687e-02],\n",
       "          [-5.7670e-02, -4.5353e-02,  2.3398e-01],\n",
       "          [-5.5263e-02,  4.3911e-02,  6.2115e-01]]],\n",
       "\n",
       "\n",
       "        [[[-4.0056e-01, -5.8748e-01, -7.7679e-02],\n",
       "          [-7.2256e-01, -1.2901e+00, -4.0942e-01],\n",
       "          [-1.0625e-01, -4.5987e-01, -8.7546e-02]],\n",
       "\n",
       "         [[ 3.2986e-01,  4.5300e-01,  2.2186e-01],\n",
       "          [ 5.3363e-01,  1.1452e+00,  5.3605e-01],\n",
       "          [ 2.0484e-01,  5.8706e-01,  2.2349e-01]],\n",
       "\n",
       "         [[ 1.1339e-01,  4.0724e-02, -1.1318e-01],\n",
       "          [ 1.2470e-01,  2.3942e-01, -4.1806e-02],\n",
       "          [-1.3700e-01, -7.2371e-02, -1.5225e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.6996e-02, -1.1178e-01, -7.9557e-03],\n",
       "          [-6.8709e-02,  1.1009e+00,  3.4087e-01],\n",
       "          [-3.4078e-02,  5.8441e-01,  2.2679e-01]],\n",
       "\n",
       "         [[-8.7361e-02, -1.8401e-01, -8.1381e-02],\n",
       "          [-3.3167e-01, -1.0462e+00, -7.2776e-01],\n",
       "          [-2.8312e-01, -8.8812e-01, -5.6615e-01]],\n",
       "\n",
       "         [[ 2.3554e-02,  5.2161e-03,  1.0610e-01],\n",
       "          [ 2.7432e-02,  6.3247e-01,  3.5427e-01],\n",
       "          [ 1.0937e-01,  5.1656e-01,  4.9538e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.8637e-01,  1.6622e-01, -1.1845e-01],\n",
       "          [ 3.0106e-01,  5.4050e-01, -1.4711e-01],\n",
       "          [-2.2641e-01, -2.1900e-01, -8.7242e-02]],\n",
       "\n",
       "         [[-1.9114e-01,  2.5089e-01, -1.5721e-01],\n",
       "          [ 4.6281e-01,  8.5613e-01, -2.3190e-01],\n",
       "          [-3.7821e-01, -4.0820e-01, -1.3814e-01]],\n",
       "\n",
       "         [[-1.3863e-01,  1.3090e-01, -8.0548e-02],\n",
       "          [ 2.3498e-01,  4.1896e-01, -1.4275e-01],\n",
       "          [-1.6995e-01, -2.0042e-01, -4.7731e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.4383e-01, -3.5976e-01, -2.2568e-01],\n",
       "          [-3.1873e-01, -6.2292e-01, -4.8455e-01],\n",
       "          [-2.9607e-01, -5.9961e-01, -5.3235e-01]],\n",
       "\n",
       "         [[ 5.3755e-02,  1.1681e-01, -1.7220e-02],\n",
       "          [ 1.3356e-01,  1.1440e-01,  1.4035e-01],\n",
       "          [ 6.1463e-02,  1.3084e-01,  1.2148e-01]],\n",
       "\n",
       "         [[ 1.1738e-01,  2.6790e-01,  1.6354e-01],\n",
       "          [ 1.6885e-01,  4.9601e-01,  3.5760e-01],\n",
       "          [ 1.7026e-01,  4.8960e-01,  3.9967e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.1143e-02,  1.4914e-01,  1.5665e-01],\n",
       "          [ 5.7058e-02,  2.5761e-01,  3.8448e-01],\n",
       "          [ 1.1824e-02,  2.3962e-02,  1.4316e-01]],\n",
       "\n",
       "         [[ 2.0644e-03,  2.4694e-01,  3.6309e-01],\n",
       "          [ 1.9455e-02,  4.8716e-01,  7.1747e-01],\n",
       "          [-3.9543e-02,  8.0655e-02,  2.8145e-01]],\n",
       "\n",
       "         [[-1.4064e-02,  6.5742e-02,  1.4198e-01],\n",
       "          [ 2.5274e-02,  9.2848e-02,  2.5258e-01],\n",
       "          [ 2.1115e-02,  5.9134e-03,  7.2156e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.8591e-02, -1.2601e-01,  1.3114e-01],\n",
       "          [ 5.1161e-02, -1.0194e+00,  1.0016e+00],\n",
       "          [ 1.2088e-02, -9.6704e-01,  9.1759e-01]],\n",
       "\n",
       "         [[ 6.2205e-03, -1.9417e-01,  2.0859e-01],\n",
       "          [ 8.3954e-02, -2.5309e+00,  2.3644e+00],\n",
       "          [ 7.6843e-03, -2.1941e+00,  2.2594e+00]],\n",
       "\n",
       "         [[ 1.5349e-03, -7.6895e-02,  7.6481e-02],\n",
       "          [ 5.2006e-02, -7.2120e-01,  6.9789e-01],\n",
       "          [ 1.1698e-02, -6.2185e-01,  5.9768e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.5708e-01,  4.0669e-01,  3.1045e-01],\n",
       "          [ 4.5320e-01,  9.6614e-01,  6.9516e-01],\n",
       "          [ 4.2314e-01,  7.9031e-01,  6.6392e-01]],\n",
       "\n",
       "         [[-8.2715e-02, -1.0448e-01, -1.1013e-01],\n",
       "          [-1.4429e-01, -3.8166e-01, -2.2852e-01],\n",
       "          [-1.2896e-01, -2.9366e-01, -2.3877e-01]],\n",
       "\n",
       "         [[-1.6368e-01, -2.3261e-01, -2.0378e-01],\n",
       "          [-2.3027e-01, -6.3410e-01, -4.0913e-01],\n",
       "          [-2.4705e-01, -5.2853e-01, -4.5905e-01]]]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters().__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "51858363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(weights.get_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "29df2112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_DataLoader__initialized',\n",
       " '_DataLoader__multiprocessing_context',\n",
       " '_IterableDataset_len_called',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_auto_collation',\n",
       " '_dataset_kind',\n",
       " '_get_iterator',\n",
       " '_index_sampler',\n",
       " '_iterator',\n",
       " 'batch_sampler',\n",
       " 'batch_size',\n",
       " 'check_worker_number_rationality',\n",
       " 'collate_fn',\n",
       " 'dataset',\n",
       " 'drop_last',\n",
       " 'generator',\n",
       " 'in_order',\n",
       " 'multiprocessing_context',\n",
       " 'num_workers',\n",
       " 'persistent_workers',\n",
       " 'pin_memory',\n",
       " 'pin_memory_device',\n",
       " 'prefetch_factor',\n",
       " 'sampler',\n",
       " 'timeout',\n",
       " 'worker_init_fn']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bced3f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f0bd98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fd4cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60795b22fbab449eaa58d146f3058605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (MPSFloatType) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m loss_fn\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m train_results\u001b[38;5;241m=\u001b[39mengine\u001b[38;5;241m.\u001b[39mtrain(model\u001b[38;5;241m=\u001b[39mmodel,train_dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader,test_dataloader\u001b[38;5;241m=\u001b[39mtest_dataloader,optimizer\u001b[38;5;241m=\u001b[39moptimizer,loss_fn\u001b[38;5;241m=\u001b[39mloss_fn,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m      7\u001b[0m train_results\n",
      "File \u001b[0;32m~/DEV/ZTM/going_modular/engine.py:167\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, test_dataloader, optimizer, loss_fn, epochs, device)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# Loop through training and testing steps for a number of epochs\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[0;32m--> 167\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m train_step(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    168\u001b[0m                                       dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader,\n\u001b[1;32m    169\u001b[0m                                       loss_fn\u001b[38;5;241m=\u001b[39mloss_fn,\n\u001b[1;32m    170\u001b[0m                                       optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m    171\u001b[0m                                       device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    172\u001b[0m     test_loss, test_acc \u001b[38;5;241m=\u001b[39m test_step(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    173\u001b[0m       dataloader\u001b[38;5;241m=\u001b[39mtest_dataloader,\n\u001b[1;32m    174\u001b[0m       loss_fn\u001b[38;5;241m=\u001b[39mloss_fn,\n\u001b[1;32m    175\u001b[0m       device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# Print out what's happening\u001b[39;00m\n",
      "File \u001b[0;32m~/DEV/ZTM/going_modular/engine.py:46\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, dataloader, loss_fn, optimizer, device)\u001b[0m\n\u001b[1;32m     43\u001b[0m X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# 1. Forward pass\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(X)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# 2. Calculate  and accumulate loss\u001b[39;00m\n\u001b[1;32m     49\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/efficientnet.py:343\u001b[0m, in \u001b[0;36mEfficientNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_impl(x)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/efficientnet.py:333\u001b[0m, in \u001b[0;36mEfficientNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 333\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures(x)\n\u001b[1;32m    335\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m    336\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[1;32m    551\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (MPSFloatType) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "optimizer=torch.optim.Adam(params=model.parameters(),lr=0.001)\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "#make sure everything is on device\n",
    "device = torch.device(\"mps\")  # Use Metal Performance Shaders on Mac\n",
    "model = model.to(device)  # Move the model to MPS\n",
    "train_dataloader = train_dataloader.to(device)  \n",
    "test_dataloader=test_dataloader.to(device)\n",
    "\n",
    "\n",
    "train_results=engine.train(model=model,train_dataloader=train_dataloader,test_dataloader=test_dataloader,optimizer=optimizer,loss_fn=loss_fn,epochs=1000,device=device)\n",
    "\n",
    "train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d528add2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480c6a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
